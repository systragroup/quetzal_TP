{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "71ccff01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training_folder': '../../scenarios/jakarta', 'params': {}}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "\n",
    "params = {}\n",
    "         \n",
    "default = {'training_folder': '../../scenarios/jakarta', 'params':params} # Default execution parameters\n",
    "manual, argv = (True, default) if 'ipykernel' in sys.argv[0] else (False, dict(default, **json.loads(sys.argv[1])))\n",
    "print(argv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "99b5db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "sys.path.insert(0, r'../../../quetzal') # Add path to quetzal\n",
    "#from quetzal.engine.road_model import RoadModel\n",
    "#from quetzal.engine.pathfinder_utils import get_path, parallel_dijkstra, build_index, sparse_matrix\n",
    "#from quetzal.engine.msa_utils import get_zone_index, assign_volume\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "#from typing import Tuple\n",
    "#from geopy.distance import geodesic  # works for geopy version >=2\n",
    "#from sklearn.cluster import KMeans\n",
    "#from syspy.spatial.spatial import nearest, agglomerative_clustering, voronoi_diagram_dataframes, add_geometry_coordinates\n",
    "#from quetzal.engine.pathfinder_utils import simple_routing,get_path\n",
    "num_cores = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "dc057466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epsg(lat: float, lon: float) -> int:\n",
    "    '''\n",
    "    return EPSG in meter for a given (lat,lon)\n",
    "    lat is north south \n",
    "    lon is est west\n",
    "    '''\n",
    "    return int(32700 - round((45 + lat) / 90, 0) * 100 + round((183 + lon) / 6, 0))\n",
    "\n",
    "def get_flight_distance(x):\n",
    "    # inputs : [(lat,lon), (lat,lon)]. or [(y,x),(y,x)]\n",
    "    # however. geodesic use lon,lat. so its inverted here\n",
    "    return geodesic(x[0], x[1]).m\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "bb087e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mesh(zones: gpd.GeoDataFrame ,step: float = 0.01) -> gpd.GeoDataFrame:\n",
    "    '''\n",
    "    create a mesh in the zones total bbox at every step (in the units of the zones crs)\n",
    "    step: degree if crs=4326, else meters.\n",
    "    '''\n",
    "    x_max, y_max = zones.bounds.max()[['maxx','maxy']].values\n",
    "    x_min, y_min = zones.bounds.min()[['minx','miny']].values\n",
    "\n",
    "    points = []\n",
    "    x = x_min\n",
    "    while x<x_max:\n",
    "        y = y_min\n",
    "        while y<y_max:\n",
    "            points.append(Point(x,y))\n",
    "            y += step\n",
    "        x += step\n",
    "    points = gpd.GeoDataFrame(geometry=points,crs=zones.crs)\n",
    "    points.index.name='index'\n",
    "    return points\n",
    "\n",
    "# https://stackoverflow.com/questions/36399381/whats-the-fastest-way-of-checking-if-a-point-is-inside-a-polygon-in-python\n",
    "from numba import jit, njit\n",
    "import numba\n",
    "@jit(nopython=True)\n",
    "def fast_point_in_polygon(x,y,poly):\n",
    "    n = len(poly)\n",
    "    inside = False\n",
    "    p2x = 0.0\n",
    "    p2y = 0.0\n",
    "    xints = 0.0\n",
    "    p1x,p1y = poly[0]\n",
    "    for i in numba.prange(n+1):\n",
    "        p2x,p2y = poly[i % n]\n",
    "        if y > min(p1y,p2y):\n",
    "            if y <= max(p1y,p2y):\n",
    "                if x <= max(p1x,p2x):\n",
    "                    if p1y != p2y:\n",
    "                        xints = (y-p1y)*(p2x-p1x)/(p2y-p1y)+p1x\n",
    "                    if p1x == p2x or x <= xints:\n",
    "                        inside = not inside\n",
    "        p1x,p1y = p2x,p2y\n",
    "        \n",
    "    return inside\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def fast_points_in_polygon(points, polygon):\n",
    "    D = np.empty(len(points), dtype=numba.boolean) \n",
    "    for i in numba.prange(0, len(points)):\n",
    "        D[i] = fast_point_in_polygon(points[i,0], points[i,1], polygon)\n",
    "    return np.where(D)[0]\n",
    "\n",
    "def points_in_polygon(points:np.ndarray, polygon:gpd.GeoDataFrame) -> np.ndarray:\n",
    "    '''\n",
    "    return a list of point in the polygon. values are the index in the points array.\n",
    "    \n",
    "    points:np.array[np.array[float,float]]\n",
    "        list of all the points coords (x,y)\n",
    "    polygon: gpd.GeoDataFrame\n",
    "        geodataframe of multiples polygons.\n",
    "    '''\n",
    "    polygon = np.array([*polygon.exterior.coords])\n",
    "    return fast_points_in_polygon(points,polygon)\n",
    "\n",
    "\n",
    "def population_to_mesh(population: gpd.GeoDataFrame, step: float=0.01,population_col='population') ->  gpd.GeoDataFrame:\n",
    "    '''\n",
    "    create a mesh in the zones total bbox at every step (in the units of the zones crs)\n",
    "    and assign the population to each node equaly (if 2 node in a zone. they have each 50% of the population)\n",
    "    population:\n",
    "        geodataframe with total population by zones ans zones geomerty\n",
    "    step: \n",
    "        degree if crs=4326, else meters.\n",
    "    '''\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    population=population.copy()\n",
    "    if population.index.name != 'index':\n",
    "        population.index.name = 'index'\n",
    "    points = create_mesh(population, step=step)\n",
    "    points_coords = np.array([point.coords[0] for point in points['geometry'].values])\n",
    "    \n",
    "    population['nodes'] = population['geometry'].apply(lambda x: points_in_polygon(points_coords,x))\n",
    "    \n",
    "    nodes = population.reset_index()[['index','nodes',population_col]].copy()\n",
    "    nodes = nodes.explode('nodes').dropna()\n",
    "    print(len(nodes[nodes['nodes'].duplicated()]),'nodes in multiple zones')\n",
    "    \n",
    "    \n",
    "    zone_index_dict = nodes.set_index('nodes')['index'].to_dict()\n",
    "    points['zone'] = points.index.map(zone_index_dict)\n",
    "\n",
    "    pop_dict = nodes.set_index('nodes')[population_col].to_dict()\n",
    "    points[population_col] = points.index.map(pop_dict)\n",
    "    points = points.dropna()\n",
    "    \n",
    "    # get number of points per zones. divide population equaly between each points\n",
    "    len_dict = points.groupby('zone')[population_col].agg(len).to_dict()\n",
    "    points['num_points'] = points['zone'].apply(lambda x:len_dict.get(x))\n",
    "    points[population_col] = points[population_col] / points['num_points']\n",
    "    points = points.drop(columns = ['num_points'])\n",
    "    \n",
    "    print(len(population) - len(points['zone'].unique()),'unfounded zones. centroids will be added to the mesh')\n",
    "    \n",
    "    # find zones not in any points of the mesh.\n",
    "    # add those zones centroid as a single mesh point.\n",
    "    zones_list = points['zone'].unique()\n",
    "    unfounded_zones = population.loc[~population.index.isin(zones_list)][['geometry',population_col]]\n",
    "    unfounded_zones['geometry'] = unfounded_zones.centroid\n",
    "\n",
    "    unfounded_zones = unfounded_zones.reset_index().rename(columns={'index':'zone'})\n",
    "    points = pd.concat([points,unfounded_zones]).reset_index(drop=True)\n",
    "    points.index.name='index'\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "4e405b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../scenarios/jakarta/inputs/pt/\n"
     ]
    }
   ],
   "source": [
    "base_folder = argv['training_folder']\n",
    "pt_folder = base_folder + '/inputs/pt/'\n",
    "input_folder = base_folder +'/inputs/'\n",
    "od_folder = base_folder + '/inputs/od/'\n",
    "output_folder = base_folder +'/outputs/'\n",
    "print(pt_folder)\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd032bd",
   "metadata": {},
   "source": [
    "# inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "7dadadbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cst_incline = argv['params' ]['constant']['cst_incline']\n",
    "#cst_road = argv['params']['road_weight']\n",
    "#cst_shared = argv['params']['shared_cycleway_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "1a674100",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = gpd.read_file(pt_folder + 'links.geojson') \n",
    "nodes = gpd.read_file(pt_folder + 'nodes.geojson')\n",
    "links = links.set_index('index')\n",
    "nodes = nodes.set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "8c5c4543",
   "metadata": {},
   "outputs": [],
   "source": [
    "population = gpd.read_file(input_folder + 'population.geojson')\n",
    "if 'index' in population.columns:\n",
    "    population = population.set_index('index')\n",
    "else:\n",
    "    population.index.name='index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "6071cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "od_file = od_folder + 'od.geojson'\n",
    "od_file_provided = os.path.isfile(od_file)\n",
    "if od_file_provided:\n",
    "    od_test = gpd.read_file(od_folder + 'od.geojson')\n",
    "    if 'name' not in od_test.columns:\n",
    "        od_test['name'] = od_test['index']\n",
    "    od_test['name'] = od_test['name'].fillna(od_test['index'].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a10e51",
   "metadata": {},
   "source": [
    "# population preapation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "785b1526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_epsg( -6.58316,106.79165)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "85f04b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid = [*population.centroid[0].coords][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "025bb758",
   "metadata": {},
   "outputs": [],
   "source": [
    "crs = get_epsg(centroid[1],centroid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "804da20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6803.724157998284"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population['area (km2)'] = population.to_crs(crs).area*1e-6\n",
    "population['area (km2)'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "26b96136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31232829.78657818"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population['population'] = population['density']*population['area (km2)']\n",
    "population['population'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d9ad9c",
   "metadata": {},
   "source": [
    "# population mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "1147ad05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71374c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = population_to_mesh(population, step=0.01, population_col = 'population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "ad942ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31232829.78657818"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['population'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "f3022c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_file(output_folder + 'population_mesh.geojson',driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e86d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632d5bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4112aafc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f3ec79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e5e485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340a2876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11dfe2fb",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e01c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42693ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
